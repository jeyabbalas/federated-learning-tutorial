# The Federated Learning Conference 2020 — Day 1 (18th June)



## Table of Contents

- [Secure NLP with SyferText](#secure-nlp-with-syfertext)
- [AI Federated Learning](#ai-federated-learning)
- [Federated Learning in the Real World](#federated-learning-in-the-real-world)
- [Rational Collaboration and Incentive Design in Federated Learning](#rational-collaboration-and-incentive-design-in-federated-learning)
- [Horizontal Federated Machine Learning](#horizontal-federated-machine-learning)
- [Distributed Deep Learning and Inference Without Sharing Raw Data— in Context of COVID-19 and Digital Health Applications](#distributed-deep-learning-and-inference-without-sharing-raw-data--in-context-of-covid-19-and-digital-health-applications)
- [Secure Federated Learning](#secure-federated-learning)
- [Federated Learning on Real World Data in Healthcare](#federated-learning-on-real-world-data-in-healthcare)
- [Predicting Healthcare Outcomes via Federated AI](#predicting-healthcare-outcomes-via-federated-ai)
- [Edge AI: Next Frontier of Enterprise Computing](#edge-ai--next-frontier-of-enterprise-computing)

____

## Secure NLP with SyferText

### Why?

1. If you had image data, you can represent your data as a numeric tensor. Even the preprocessing in images are tensor operations. But in NLP we need non-trivial **pre-processing** including tokenization, padding, tagging, and convert into vector representation or embedding.
2. Servers would like to deploy the preprocessing pipelines for new clients in a federation.

### Who?

[Alan Aboudib](https://blog.openmined.org/author/alan/) is the creator of [SyferText](https://github.com/OpenMined/SyferText) and NLP team lead at [OpenMined](https://www.openmined.org/).

### What?

1. SyferText is an open source, privacy-preserving NLP library. It has two use cases—
   1. **Secure plaintext pre-processing**: Allows clients to specify pre-processing components locally and converts into tensor for ML.
   2. **Secure pipeline deploy**: Allows secure deployment of preprocessing pipelines to clients to process locally.

### How?

1. SyferText users—
   1. **Data scientists**: Preprocesses the string that exists remotely and train the NLP model. They'd first create a *language model*. The call a language model on SyfertText String objects that don't contain plain text data but contain pointers to remote data. They also design pre-processing pipelines (syntax similar to *SpaCy*). SyferText sends a copy preprocessing pipelines (called *subpipelines*) to clients. They process strings remotely and generate doc objects. The document object is encrypted and sent for batch training to the server. The trained model is then deployed.
   2. **Data owners**: Search for available pipelines and import one. Send local string data through the pipeline. Generate doc object. Convert into encrypted vector. Get encrypted model prediction from server as another document object. Decrypt it to use prediction.

### References

1. SyferText: https://github.com/OpenMined/SyferText

____

## AI Federated Learning

### Why?

1. Leading enterprises adopting AI include— finance, healthcare, retail, and manufacturing. Together they account for 57% of the use cases.
2. By 2025, 28% of AI hardware will be at the edge and 41M IoTs will generate 79 ZB of data. The enterprise AI is evolving towards federated learning because enterprises have to generate business value and there is high value is moving the models (inferencing and eventually training) to the edge.

### Who?

[Marcin Rojek](https://www.linkedin.com/in/marcinrojek/) is a co-founder of [byteLAKE](https://www.bytelake.com/en/), a start-up, based in Poland, for building AI and HPC solutions. [Robert Daigle](https://www.linkedin.com/in/rdaigle/) is an AI Innovation & Business Leader at Lenovo, USA.

### What?

1. **Edge AI**: Running AI for inferencing at the edge.
2. **Federated Learning**: Model training done to improve AI models on the edge.

### How?

1. **Edge AI**: Enables scalability, allows processing data in real-time, low latency, reduced bandwidth needs, low cost of ownership, and data can reside locally at the device. But AI models need to be highly optimized for low compute and energy resources at the edge.
2. Applications of Edge AI by byteLAKE includes—
   1. **Traffic analytics**: Real-time video input and counts number of objects on the road (pedestrians, cars, etc.) Edge device includes small devices like Raspberry Pi powered by Intel videos and USB camera. Raspberry Pi did not have to store video data. Data detection was done and info sent to Azure cloud which did advanced analytics.
   2. **Loss prevention in retail**: Video monitoring of self-checkouts to prevent errors in scanning.
   3. **Illegal Dumping Detection**: EwaGuard detects illegal dumping areas. Edge device like drones take pictures of areas and does on device prediction. This reduces the data that needs to be communicated to the EwaGuard server. Sends coordinates and alerts to the server.
3. **Federated AI**: Has the same benefits as Edge AI and additionally provides data privacy.
4. Application of Federated Learning by byteLAKE and Lenovo—
   1. Edge devices are Lenovo ThinkCentre Tiny Desktops that can be connected to edge components in factories. Tiny desktops were training a time-series model across a network of tiny desktops. Edge devices obtained the trained model for prediction.

### References

1. Federated learning demo by byteLAKE: https://youtu.be/bHo8YS5sNRE

____

## Federated Learning in the Real World

### Why?

1. **Edge devices**: All devices that generate data and have substantial computational power for processing the data. It includes mobiles, self-checkout, camera, CPU, etc. Today edge devices are mostly used for inference and not for training. Federated learning involves training models on edge devices on local data, then sharing to create a global model.
2. **Challenges** of running distributed computing in edge devices—
   1. Number of participating edge devices. Google has 10-100 million mobile phones in the federation.
   2. Distribution of data among the edge devices. Data may be non-IID. Each device deals with a different data diatribution.
   3. Network bandwidth and latency. 

### Who?

[Nadav Israel](https://www.linkedin.com/in/nadav-israel-4b845744/) is a co-founder and Chief Technology Officer at [Edgify](https://www.edgify.ai/), a start-up based in Israel focussed on edge AI.

### What?

1. **Large Batch Stochastic Gradient Descent**: Initialize global model.
   1. Edge devices: Download current global model. Run single pass of forward and backward propagation. Compress gradients. Upload gradients to server.
   2. Server: Decompress gradients. Compute average of gradients. Perform single step of stochastic gradient descent (SGD). Update global model.
2. **Federated Averaging**: Initialize global model.
   1. Edge devices: Download current global model. Run a number of SGD steps. Compress model weights. Upload weights to server.
   2. Server: Decompress model weights. Compute average weights. Update global model.

### How?

1. Evaluation summary over several experiments showed the following—

|                                       | Large Batch                               | Federated Averaging                       |
| ------------------------------------- | ----------------------------------------- | ----------------------------------------- |
| Compared to centralized deep learning | Conservative (better)                     | Radical                                   |
| Number of epochs                      | Standard (better)                         | Increased                                 |
| Communications rounds needed          | Large                                     | Reduced (better)                          |
| Effective compression methods         | Use Deep Gradient Compression (better)    | Use Quantization                          |
| Batch normalization with non-IID data | Group normalization, Fixup initialization | Group normalization, Fixup initialization |
| Non-IID data                          | Manages to perform well (better)          | Struggles to converge                     |

2. Federated Averaging is better for scarce connectivity and IID data.
3. Large Batch SGD is better for steady communication, non-IID data, and when large compression rates are required.

### References

1. [Shoham N, Avidor T, Keren A, Israel N, Benditkis D, Mor-Yosef L, Zeitak I. Overcoming Forgetting in Federated Learning on Non-IID Data. arXiv preprint arXiv:1910.07796. 2019 Oct 17.](https://arxiv.org/pdf/1910.07796.pdf)

____

## Rational Collaboration and Incentive Design in Federated Learning

### Why?

1. Data is valuable to each entity. It exists as silos, is restricted under privacy regulations, and there are practical blockers that is difficult to share (e.g. high frequency data from IoT, large datasets, unreliable networks, etc.).
2. How do you collaborate to produce a ML model among competitors? Some benefits include: all collaborators may have a shared problem they want to mutually solve or collaboration can also achieve highly optimal solution to any problem. 

### Who?

[Daniel Zakrisson](https://se.linkedin.com/in/danielzakrisson) is the CEO and co-founder of [Scaleout Systems](https://scaleoutsystems.com/), a Sweden-based start-up focussing on production of privacy-preserving machine learning systems.

### What?

1. A trusted party orchestrates the federation process (the server).
   1. To increase trust with the server— 1) provide auditable runtimes that can be verified by clients, and 2) audit trails and public logs are made available to clients.
   2. If the clients don't trust the server— 1) run code in secure, tamper-proof, secured enclaves; 2) prevent data leakage using secure MPC and Homomorphic Encryption; and 3) use open-source, immutable audit trails. If the source-code is open-source, the clients can verify if the code does what it is supposed to do. Software fingerprinting to ensure correct version of a software is running. Provide immutable audit trails (using blockchains) available for all alliance members.
2. Clients trust each other to not try and sabotage the model (*model poisoning attacks*) or try to recreate other's data (*model inference attacks*).
   1. Preventing data poisoning attacks: 1) assign a validation dataset for each client to pass before they make a submission to the orchestrator; 2) assign a fee each time a client makes a contribution and proportionally reward client by their contribution to the improvement of the global model.
   2. Preventing model inference attacks: 1) global limit on number of inferences, 2) individual limit on inferences, and 3) incremental cost of inferences.
3. Clients want to be reimbursed for their contribution but will contribute as much as they can without additional incentives.
   1. Profit sharing schemes: Egalitarian, Marginal gain (Shapley), Marginal loss.
   2. Reverse auctions: Data owners set a price for their participation. Other data controllers bid to include a client into the alliance.
   3. Bounties: Alliance set a fixed/dynamic reward if their update creates a defined improvement.
   4. Reputation-based schemes: assign contribution score to members.
   5. Intrinsic motivation: Personally-rewarding (non-financial rewards like contributing to an open-source models), cause-driven (collaborative solution can solve a common problem).
4. Assessing contribution/reward for a client—
   1. Bonding curves: Help automate relationship between supply and cost. Demand side: High incentives for early contribution that grows smaller over time. Calculate reward based on model accuracy. Supply side: Cheap cost of inferencing early on when the model accuracy is poor. Inference cost grows as model accuracy is improved. 
   2. If the overhead of setting up a federation is high, assign fees for joining a federation.

### How?

1. Improving trust and adding financial incentives (to boost contributions) helps to improve the overall quality of the federated alliance.

### Reference

1. Full talk on YouTube: https://www.youtube.com/watch?v=uSG2T2d3hiQ

____

## Horizontal Federated Machine Learning

### Why?

1. **Challenges** of federated learning—
   1. **Statistical heterogeneity**: data is often highly non-IID across the clients. This affects model convergence and accuracy. Possible solution— generate a globally shared data (https://arxiv.org/pdf/1806.00582.pdf).
   2. **System heterogenity**: Asynchronous client updates due to hardware heterogenity can affect model convergence. *Stragglers* are clients that submit delayed updates. Possible solutions— 1) drop stragglers, 2) allow delayed updates, or 3) modify objective function to penalize the weights of late updates (https://arxiv.org/pdf/1812.06127.pdf).
   3. **Scalability**: Number of clients can be very large leading to problems in client-server communication (weak connections, infeasibility of deploying large models, or if server does not scale).

### Who?

[Andreas Hellander](https://andreashellander.se/) is a professor at Uppasala University and the CSO of [Scaleout Systems](https://scaleoutsystems.com/), a Sweden-based start-up focussing on production of privacy-preserving machine learning systems.

### What?

1. **FEDn**: An open-source system for federated learning. Enables ML on private, siloed, and regulated data. The framework contains three layers—1) *Client layer* involving computations performed on clients i.e., the data nodes; 2) *Orchestrator layer* one or many stateless agents that combine models from different clients; 3) *Reducer layer*: Single node that aggregates models from different orchestrators and prepare model for inference.
2. Each node in FEDn can perform model validation locally. FEDn also provides alliance messages, timeline of model construction, and immutable audit trails using Ethereum blockchain. FEDn uses scalable gRPC communication and MongoDB.

### How?

1. In classic Federated Averaging, there is one Orchestrator and one Reducer and they both have the same role. To **scale up and parallelize Federated Averaging**, introduce multiple Orchestrators that are then aggregated by a Reducer.
2. **Metamodeling**: Multiple orchestrators generate multiple models. They can be aggregated in an ensemble scheme like Bagging. This helps with data heterogeneity. This system can also help in alliance governance where poisoned updates can be removed before aggregation by the Reducer.

### References

1. Open-source collaborative AI platform STACKn: https://github.com/scaleoutsystems/stackn
2. Full talk on YouTube: https://www.youtube.com/watch?v=9WLG9XtCXwU

____

## Distributed Deep Learning and Inference Without Sharing Raw Data— in Context of COVID-19 and Digital Health Applications

### Why?

1. **Digital contact tracing for COVID-19**: Using smartphones to give notifications of proximity information (from GPS and bluetooth) to individuals who have interacted with COVID-19 infected individuals. To prevent a creation of a surveillance state, the information about the individuals must be kept private. 
2. There are at least 4 broad methods of privacy-preserving ML, each with varying degrees of data privacy and utility for machine learning.
   1. *Anonymization* using tools like Strava. Provides low data privacy since overlapping datasets can reidentify the individual. But anonymized data is convenient for ML-related computations.
   2. *Obfuscating* using methods like Differential Privacy. Provides slightly better privacy but affects ML training efficiency.
   3. *Smashing* using their proposed Split Learning method. Provides more privacy but will affect ML training further.
   4. *Encrypting* using methods like Homomorphic Encryption. Offers high privacy. Is good for making simple statistical queries but makes it difficult to do full-fledged ML.
3. **Digital health applications**: Data is often present as silos. We often have computation resources available at places without data and data available without good computation resource (e.g. IoT devices). Large ML models like transformers are very computation resource-intensive.
4. **Problems with Federated Learning**: 1) All compute must happen on each client device; 2) doesn't converge well on heterogeneous data (different distributions); and 3) doesn't scale well with large number of clients.

### Who?

[Ramesh Raskar](https://www.media.mit.edu/people/raskar/overview/) is an Associate Professor and the head of the MIT Media Lab's [Camera Culture](https://www.media.mit.edu/groups/camera-culture/overview/) research group. [Abhishek Singh](https://www.media.mit.edu/people/abhi24/overview/) is a graduate student working with Ramesh Raskar at the MIT Media Lab's [Camera Culture](https://www.media.mit.edu/groups/camera-culture/overview/) research group.

### What?

1. **Split Learning**: The DL network is split at a designated *split layer*. The server trains the lower levels (below the split layer), while the clients train the upper levels of the neural network. Only the activations from the split layer is communicated between the client and the server.
2. Various network topologies accommodate the different requirements of the implementation. For example, *vanilla topology* when raw data exists with clients but labels with the server; *boomerang topology* when both the raw data and labels exist with the clients; *vertical partitioning topology* when clients contain different subsets of features for the same set of examples; and various other hybrid topologies.
3. Split Learning was applied to solve the problem of COVID-19 contact tracing in a privacy-preserving manner. This open-source project is called COVID SafePaths (https://covidsafepaths.org/). The app performs contact tracing, symptom check, communicate with public health officials, decision making on testing and/or isolating, telehealth solutions, etc.

### How?

1. Compared to Federated Learning, Split Learning is more communication-efficient when the number of clients is large or when the size of the model is large. Although, it is safer to communicate parameters than sharing activations (as in case of Split Learning).

### References

1. Project page: https://splitlearning.github.io/.
2. [Singh A, Vepakomma P, Gupta O, Raskar R. Detailed comparison of communication efficiency of split learning and federated learning. arXiv preprint arXiv:1909.09145. 2019 Sep 18.](https://arxiv.org/pdf/1909.09145.pdf)
3. Papers from MIT's COVID-19 SafePaths: https://github.com/PrivateKit/PrivacyDocuments
4. Split learning is also ported into the open sourced platform PySyft (https://github.com/OpenMined/PySyft).

____

## Secure Federated Learning

### Why?



### Who?



### What?



### How?



### References

____

## Federated Learning on Real World Data in Healthcare

### Why?



### Who?



### What?



### How?



### References

____

## Predicting Healthcare Outcomes via Federated AI

### Why?



### Who?



### What?



### How?



### References

____

## Edge AI: Next Frontier of Enterprise Computing

### Why?



### Who?



### What?



### How?



### References



