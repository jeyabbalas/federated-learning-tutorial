# The Federated Learning Conference 2020 â€” Day 2 (19th June)

____

## Split Learning and NoPeek for Resource Efficient Distributed Deep Learning

### Why?

1. **Goal of distributed computing**: How can we effectively enable individual, organizational, regional, national, and global collaboration through data and intelligence sharing, without infringing privacy, security, safety, trust, and regulation?
2. **Resource efficiency**: For a solution to be widely deployed, it needs to be resource efficient. It should work in situations like low availability of data, low communication bandwidth, and low compute resources.
3. **Overall goal**: Private and efficient distributed machine learning without exchnage of raw data.
4. **Challenges with existing solutions**: *Federated Learning* can be challenging in low-resource environments when deploying large models with millions of parameters.

### Who?

[Praneeth Vepakomma](https://www.media.mit.edu/people/vepakom/overview/) is a researcher at  [MIT's Camera Culture group](https://www.media.mit.edu/groups/camera-culture/overview/). He works on algorithms development for distributed and collaborative machine learning.

### What?

1. **Split learning**: The DL model is split at a designated layer called *split layer*. The server trains the lower levels (below the split layer), while the clients train the upper levels of the neural network. Only the activations from the split layer is communicated between the client and the server.
2. Various network topologies accommodate the different requirements of the implementation. For example, *vanilla topology* when raw data exists with clients but labels with the server; *boomerang topology* when both the raw data and labels exist with the clients; *vertical partitioning topology* when clients contain different subsets of features for the same set of examples; and various other hybrid topologies.
3. **Reconstruction attacks**: Input raw data can be reconstructed by an adversary who gets access to the activations being communicated.
   1. *Note*: There are other types of attacks possible, which are part of ongoing research.
4. **NoPeek method (to prevent reconstruction attacks)**: Instead of using a plain loss function like *categorical cross entropy*, add a *leakage term* to the loss function that attempts to decorrelate the input data and the activations being coimmunicated. Introduce a hyperparameter to control the amount of leakage. The leakage term can also be designed to specifically obfuscate only certain sensitive attributes.

### How?

1. Split network training reduces the amount of computation required by the clients and the amount of information that needs to be communicated between the clients and the server.
2. Split learning was evaluated on four benchmark medical imaging datasets, each modeled using large networks like VGG and ResNet. When compared with federated learning and large-scale Stochastic Gradient Descent, split learning was shown to result in significant savings in client-side computation and communication.
3. NoPeek method considerably obfuscates the input image making it very difficult to reconstruct the input data. The leakage term hyperparameter represents a tradeoff in privacy and utility. Greater the value of the hyperparameter, the greater the privacy (harder to reconstruct the input) but lower the model accuracy. Lesser the value of the hyperparameter, lower the privacy but greater the model accuracy.

### References

1. Project page: https://splitlearning.github.io/.
2. [Vepakomma P, Gupta O, Swedish T, Raskar R. Split learning for health: Distributed deep learning without sharing raw patient data. arXiv preprint arXiv:1812.00564. 2018 Dec 3.](https://arxiv.org/pdf/1812.00564.pdf)
3. Split learning is also ported into the open sourced platform PySyft (https://github.com/OpenMined/PySyft).

____

