# The Federated Learning Conference 2020 — Day 2 (19th June)

## A High-performance End-to-end Heterogeneous Infrastructure for Accelerating Federated Machine Learning

### Why?

1. To enable secured federated learning, we must encrypt the parameters shared via networks between the clients and the servers. One such method is **Homomorphic Encryption (HE)**. There are two types of HE algorithms— 1) *partial HE*, which only supports one of either addition or multiplication, and 2) *full HE*, which enables both addition and multiplications. 
2. **HE challenges**: Partial HE is 100 times more computationally complex than raw data. Full HE is further 100 times more computationally complex than partial HE. This significantly increases the transmission load.

### Who?

[Shuihai Hu](https://www.linkedin.com/in/shuihai-hu-2a9b51b0/) is a Chief Scientist at [Clustar](https://www.clustar.ai/en), an AI-based startup located in Beijing, Shenzhen, and Hong Kong.

### What?

1. **Heterogeneous Infrastructure for Federated Machine Learning**: Clustar have designed a federated machine learning library that contains libraries of federated machine learning algorithms supported by accelerators for different hardwares like GPUs and FPGAs. It also contains libraries for security protocols for federated networking modules. Networking is speed-up via accelerators for RDMA and ExpressPass. These accelerators help speed-up computations using HE.
2. Speed-up computation using GPU acceleration by solving the following three challenges.
   1. Problem: GPUs don't support large number arithmetic. Proposed solution: recursive decomposition with divide and conquer.
   2. Problem: Expensive modular exponentiation. Proposed solution: Square-and-multiply + Montgomery modular multiplication.
   3. Problem: Need large cache to store intermediate results. Proposed solution: Chinese remainer theorem to cut intermediate results.
3. Speed-up networking using RDMA accelerators.
   1. In intra-datacenter scenario (within an organization), how to accelerate data transfer in high-speed networks? Proposed solution: RDMA for one-to-one acceleration. Dynamic parameter aggregation for many-to-one.
   2. In inter-datacenter scenario (between organizations), how to accelerate data transfer in networks with large delay and frequent packet loss? Proposed solution: Specially designed network transport.

### How?

1. Their GPU accelerators achieve a 5.8x speed-up for encryption, 5.93x for decryption, 31.4x for multiplication, and 419x on addition.
2. Networking speed-up of 10-100x over a TCP network.

____

## Putting Privacy into Federated Learning

### Why?



### Who?



### What?



### How?



____

## Two-stage Federated Phenotyping and Patient Representation Learning

### Why?

1. ML model training requires a lot of data. But data privacy laws like HIPAA in the US and GDPR in the European Union, make it challenging to share medical data from different silos.
2. **Clinical notes** contain a rich and reliable source of health data. Notes include discharge summaries, nursing notes, and notes from different specialists. Clinical notes are highly confidential. But access to such data for ML algorithms can help realize *precision medicine*.
3. **Standardization for Federated Learning**: Architecture for collaboration may already be in place, for example— [i2b2 network](https://www.i2b2.org/), [ACT network](https://www.ctsi.umn.edu/consultations-and-services/multi-site-study-support/accrual-clinical-trials-act-network), and [UDN network](https://undiagnosed.hms.harvard.edu/). Additionally, [HL7 FHIR](https://www.hl7.org/fhir/) can help specify stadardized data formats for various clients in a federation system.

### Who?

[Dianbo Liu](https://scholar.harvard.edu/dianboliu/bio) is a research fellow in Computational Health Informatics Program (CHIP) at Harvard Medical School and Boston Childrens's Hospital.

### What?

1. **Two-stage Federated Phenotyping and Patient Representation Learning**: This federated learning system occurs in two stages—
   1. *Stage 1* (**Patient Representation Learning**): In this step, guided by a medical expert, clinical notes are parsed to identify medical concepts. Medical concepts are encoded using their UMLS Concept Unique Identifiers (CUIs). CUIs are encoded using a word embedding. Embedding is trained in a supervised way using ICD/CPT codes relevant to a patient during their visit, when the notes were taken. The layers before the output layer (ICD/CPT code vector) is used as a patient representation.
   2. *Stage 2* (**Phenotype Learning**): Trained embedded takes clinical notes as input and predicts phenotype as output.

### How?

1. Method was tested on  the open source i2b2 MIMIC dataset. Various phenotypes were chosen for evaluation.
2. They evaluated 3 types of patient representation learning— 1) bag-of-CUIs, 2) embedding from centralized data, and 3) embedding from federated data. For each, they evaluated two types of learning on phenotypes— 1) centralized training, and 2) federated training.
3. Model with patient representations learned using federated system and phenotype learning using the federated system outperformed all the other evaluated model combinations on Precision, Recall, and F1 score. The result was consistently good for various phenotypes.

### References

1. [Liu D, Dligach D, Miller T. Two-stage federated phenotyping and patient representation learning. arXiv preprint arXiv:1908.05596. 2019 Aug 14.](https://arxiv.org/pdf/1908.05596.pdf)
2. The source code will be made available at: https://github.com/kaiyuanmifen/FederatedNLP

____

## Split Learning and NoPeek for Resource Efficient Distributed Deep Learning

### Why?

1. **Goal of distributed computing**: How can we effectively enable individual, organizational, regional, national, and global collaboration through data and intelligence sharing, without infringing privacy, security, safety, trust, and regulation?
2. **Resource efficiency**: For a solution to be widely deployed, it needs to be resource efficient. It should work in situations like low availability of data, low communication bandwidth, and low compute resources.
3. **Overall goal**: Private and efficient distributed machine learning without exchnage of raw data.
4. **Challenges with existing solutions**: *Federated Learning* can be challenging in low-resource environments when deploying large models with millions of parameters.

### Who?

[Praneeth Vepakomma](https://www.media.mit.edu/people/vepakom/overview/) is a researcher at  [MIT's Camera Culture group](https://www.media.mit.edu/groups/camera-culture/overview/). He works on algorithms development for distributed and collaborative machine learning.

### What?

1. **Split learning**: The DL model is split at a designated layer called *split layer*. The server trains the lower levels (below the split layer), while the clients train the upper levels of the neural network. Only the activations from the split layer is communicated between the client and the server.
2. Various network topologies accommodate the different requirements of the implementation. For example, *vanilla topology* when raw data exists with clients but labels with the server; *boomerang topology* when both the raw data and labels exist with the clients; *vertical partitioning topology* when clients contain different subsets of features for the same set of examples; and various other hybrid topologies.
3. **Reconstruction attacks**: Input raw data can be reconstructed by an adversary who gets access to the activations being communicated.
   1. *Note*: There are other types of attacks possible, which are part of ongoing research.
4. **NoPeek method (to prevent reconstruction attacks)**: Instead of using a plain loss function like *categorical cross entropy*, add a *leakage term* to the loss function that attempts to decorrelate the input data and the activations being coimmunicated. Introduce a hyperparameter to control the amount of leakage. The leakage term can also be designed to specifically obfuscate only certain sensitive attributes.

### How?

1. Split network training reduces the amount of computation required by the clients and the amount of information that needs to be communicated between the clients and the server.
2. Split learning was evaluated on four benchmark medical imaging datasets, each modeled using large networks like VGG and ResNet. When compared with federated learning and large-scale Stochastic Gradient Descent, split learning was shown to result in significant savings in client-side computation and communication.
3. NoPeek method considerably obfuscates the input image making it very difficult to reconstruct the input data. The leakage term hyperparameter represents a tradeoff in privacy and utility. Greater the value of the hyperparameter, the greater the privacy (harder to reconstruct the input) but lower the model accuracy. Lesser the value of the hyperparameter, lower the privacy but greater the model accuracy.

### References

1. Project page: https://splitlearning.github.io/.
2. [Vepakomma P, Gupta O, Swedish T, Raskar R. Split learning for health: Distributed deep learning without sharing raw patient data. arXiv preprint arXiv:1812.00564. 2018 Dec 3.](https://arxiv.org/pdf/1812.00564.pdf)
3. Split learning is also ported into the open sourced platform PySyft (https://github.com/OpenMined/PySyft).

____

