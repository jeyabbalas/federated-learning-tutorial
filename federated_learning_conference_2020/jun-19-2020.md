# The Federated Learning Conference 2020 — Day 2 (19th June)

## Table of Contents

- [A High-performance End-to-end Heterogeneous Infrastructure for Accelerating Federated Machine Learning](#a-high-performance-end-to-end-heterogeneous-infrastructure-for-accelerating-federated-machine-learning)
- [Putting Privacy into Federated Learning](#putting-privacy-into-federated-learning)
- [Traceable Distributed Learning on Sensitive Health Data](#traceable-distributed-learning-on-sensitive-health-data)
- [Federated Analytics on Real-life Healthcare Data](#federated-analytics-on-real-life-healthcare-data)
- [Two-stage Federated Phenotyping and Patient Representation Learning](#two-stage-federated-phenotyping-and-patient-representation-learning)
- [Split Learning and NoPeek for Resource Efficient Distributed Deep Learning](#split-learning-and-nopeek-for-resource-efficient-distributed-deep-learning)
- [Privacy Preserving Federated Learning](#privacy-preserving-federated-learning)
- [Transforming Supply Chain with Blockchain and AI](#transforming-supply-chain-with-blockchain-and-ai)
- [Practical Explainable AI](#practical-explainable-ai)

____

## A High-performance End-to-end Heterogeneous Infrastructure for Accelerating Federated Machine Learning

### Why?

1. To enable secured federated learning, we must encrypt the parameters shared via networks between the clients and the servers. One such method is **Homomorphic Encryption (HE)**. There are two types of HE algorithms— 1) *partial HE*, which only supports one of either addition or multiplication, and 2) *full HE*, which enables both addition and multiplications. 
2. **HE challenges**: Partial HE is 100 times more computationally complex than raw data. Full HE is further 100 times more computationally complex than partial HE. This significantly increases the transmission load.

### Who?

[Shuihai Hu](https://www.linkedin.com/in/shuihai-hu-2a9b51b0/) is a Chief Scientist at [Clustar](https://www.clustar.ai/en), an AI-based startup located in Beijing, Shenzhen, and Hong Kong.

### What?

1. **Heterogeneous Infrastructure for Federated Machine Learning**: Clustar have designed a federated machine learning library that contains libraries of federated machine learning algorithms supported by accelerators for different hardwares like GPUs and FPGAs. It also contains libraries for security protocols for federated networking modules. Networking is speed-up via accelerators for RDMA and ExpressPass. These accelerators help speed-up computations using HE.
2. Speed-up computation using GPU acceleration by solving the following three challenges.
   1. Problem: GPUs don't support large number arithmetic. Proposed solution: recursive decomposition with divide and conquer.
   2. Problem: Expensive modular exponentiation. Proposed solution: Square-and-multiply + Montgomery modular multiplication.
   3. Problem: Need large cache to store intermediate results. Proposed solution: Chinese remainer theorem to cut intermediate results.
3. Speed-up networking using RDMA accelerators.
   1. In intra-datacenter scenario (within an organization), how to accelerate data transfer in high-speed networks? Proposed solution: RDMA for one-to-one acceleration. Dynamic parameter aggregation for many-to-one.
   2. In inter-datacenter scenario (between organizations), how to accelerate data transfer in networks with large delay and frequent packet loss? Proposed solution: Specially designed network transport.

### How?

1. Their GPU accelerators achieve a 5.8x speed-up for encryption, 5.93x for decryption, 31.4x for multiplication, and 419x on addition.
2. Networking speed-up of 10-100x over a TCP network.

____

## Putting Privacy into Federated Learning

### Why?

1. Our lives are increasingly losing privacy because of the nature of technology.
   1. **Secret Profiling & Personalization**: We put out many personal secrets on tools like internet search engines.
   2. **Voice assistant**: Voice assistants like Alexa are designed to constantly listen to us (https://www.theguardian.com/technology/2019/oct/09/alexa-are-you-invading-my-privacy-the-dark-side-of-our-voice-assistants).
2. Plain federated learning involves sharing of locally trained parameters, which can be deciphered by an adversary.

### Who?

[Michael Huth](https://www.linkedin.com/in/michael-huth-b5109917/) is the Chief Technology Officer and co-founder of [XAIN AG](https://www.xain.io/), a Berlin-based start-up focussing on AI utilization with data privacy. He is also a Professor of Computer Science at Imperial College London.

### What?

1. **Masked Federated Learning**: A framework (developed in RUST) to ensure user privacy and data confidentiality. In the following the *Update Participants* and *Sum Participants* are different roles assigned to the clients. *Coordinator* and *Enterprise* are different roles assigned to the server system.
   1. A *Coordinator* (can be hosted within an *Enterprise* or maybe a third party) initializes a global model and sends to randomly chosen *Update Participants*.
   2. *Update Participants* locally train the global model to get a local model. They each mask their local parameters by adding a pseudo-randomly generated value. The seed of the pseudo-random generator is common knowledge among particpants. These masked values are now sent to the *Coordinator*.
   3. The *Coordinator* sends the masked values to *Sum Participants*. The *Coordinator* then aggregates the masked values and sends it to the *Enterprise*.
   4. A set of *Sum Participants* are randomly chosen now. Using the seed of the pseudo-random number generator, they re-generate the random values generated by *Update Participants*. The random numbers used for masking are sent to the *Enterprise*. 
   5. The *Enterprise* unmasks the aggregated value from the *Coordinator* using the masking values sent by the *Sum Participants*. The *Enterprise* then uses the updated value to update the global model and re-iterates these steps in the protocol.

### How?

1. Enables federated learning at scale with millions of client devices.

### References

1. Whitepaper: https://www.xain.io/federated-learning-technology
2. Documentation: https://docs.xain.io/
3. GitHub repository: https://github.com/xainag/xain-fl

____

## Traceable Distributed Learning on Sensitive Health Data

### Why?

1. **Owkin Software Stack** includes 1) *Owkin Studio*, a tool for medical experts to visualize data and model output; and 2) *Owkin Connect*, a platform for federated learning with high privacy and traceability. 
   1. *Privacy* ensures data remains at its data location and input data cannot be retrieved from models.
   2. *Traceability* allows transparency for the clients to understand how the data was utilized, verify the claimes of model performance by the server, and helps quantify the fair assessment of value contribution by each federated clients.
2. **Heathchain project**: Application of distributed learning over 7 academic medical centers, 2 research centers, and 2 start-ups. Goal was to develop predictive models of treatment outcomes in Breast Cancer, and image classification of Melanoma. Deployed behind firewalls of the health institutions. 
3. **Melloddy project**: Funded by European commission to apply federated learning for drug discovery from data from 10 pharmaceutical companies.

### Who?

[Camille Marini](https://www.linkedin.com/in/camille-marini-b585b210/) is the Vice President of Engineering at [Owkin](https://owkin.com/), a France-based start-up that uses ML for development of effective therapies for patients. They use data from hospitals, universities, and pharmaceutical companies to— 1) answer why drug efficacy differs between patients? 2) enchance drug development, and 3) identify optimal therapy for a patient.

### What?

1. Owkin Connect is a proprietary software with an open-core business model. Closed-source tools include— tools for data preparation, ML algorithms, federated learning strategies, privacy-preserving methods, and interfaces for data scientists. Open-source core (called Substra) tools include tools for traceable ML for decentralized sensitive data.

### How?

1. Data privacy and traceability methods are data-agnostic, algorithm-agnostic, and framework-agnostic (e.g. Pytorch, TensorFlow, etc.)
2. There are two networks created for the orchestration of federated learning—
   1. **Model network**: responsible for exchange of models. Done using REST API by a Model Dispatcher node.
   2. **Metadata network**: responsible for orchestration of metadata. Contains non-sensitive information needed for permissions (who is allowed to compute on my dataset), learning, and traceability. This information can help trace and reproduce the model training process. This technology is open-source by Linux foundation (https://www.hyperledger.org/).

### References

1. Open-source core of Owkin Connect: https://github.com/SubstraFoundation

____

## Federated Analytics on Real-life Healthcare Data

### Why?

1. Application use case: Predicting length of stay of patients. We would like to gather data from several hospitals. Clean and pre-process data. Train model and deploy. However, in the real-world, there are many challenges— we need authorization to share data, non-trivial to aggregate data from different sources, need to give IT folks access to data, map the data to a common format, we realize during model building that we need more data/features.
2. **Challenges**—
   1. **Standardization**: Each hospital contains different softwares (for vitals, biology, urgency, etc.) each having their own databases with their own format (schema, units). So, within each hospital the data for a single patient is siloed. There are several hospitals we want to collaborate with. 
   2. **Decentralized computation**: For federated learning, the computation has to be done on decentralized datasets.
   3. **Privacy**: In a federated system, an adversary can retro-engineer the input data.
   4. **Mutual trust**: In a federated system, the clients must not have access to each other's data or model to retro-engineer each other's data.

### Who?

[Théo Ryffel](https://www.di.ens.fr/theo.ryffel/) is a co-founder and Chief Technology Office of [Arkhn](https://arkhn.com/en/), a startup based at Paris, France. Arkhn collaborate with healthcare institutions and provide privacy-preserving data solutions as APIs. Théo is also a contributer to open-source platforms like TensorFlow, PyTorch, and OpenMined (specifically for PySyft).

### What?

1. **Standardization**: Transform different data into a common standardized format called HL7 FHIR (since 2014) using an open source tool called [Pyrog](https://github.com/arkhn/pyrog). FHIR provides API to query all standard databases in the world. Open-source tool for converting FHIR database into ML-friendly form— [FHIR2Dataset](https://github.com/arkhn/FHIR2Dataset).
2. **Decentralized computation**: If the hospital databases can be queried with a standard API, we can use a common distributed SQL query on FHIR data across the institutions using [PySyft](https://github.com/OpenMined/PySyft).

```python
alice = NodeClient("ws://localhost:7600")
bob = NodeClient("ws://localhost:7601")
charlie = NodeClient("ws://localhost:7602")

grid = sy.PrivateGridNetwork(alice, bob, charlie)

dataset = grid.api.fhir\
.select(Patient.id, Patient.gender)\
.from(Patient)\
.where(Patient.birthdate='<2000-01-01')
```

3. **Privacy**: Arkhn uses differential privacy (Dwork et. al., 2014) adding random noise to communicated updates. Amount of noise represent a trade-off between privacy and model accuracy. To optimize its use, create a moment accountant (Abadi et al., 2016) that budgets the amount of privacy that can be accommodated to each client. This part of the project will be made open-source in PySyft in July 2020.
4. **Mutual trust**: We can use Homomorphic Encryption or Secure Multi-Party Computation (MPC) to keep both data and model private. Using MPC, data can only be decrypted if everyone agrees (shared governance). All important computations needed for deep learning can be done in MPC. An open-source library is being developed in OpenMined called AriaNN.

### How?

1. **Standardization**: Pyrog and FHIR2Dataset helps obtain ML-friendly formatted datasets from different standard datasets.
2. **Decentralized computation**: PySyft can be used to perform decentralized queries to the different remote databases as follows.

For remote clients we use PySyft as follows—

```python
# Locate remote workers
hospital_A = WebsocketClientWorker(id="A", port=8777, host"<host A>")
hospital_B = WebsocketClientWorker(id="B", port=8778, host"<host B>")

# Get pointers to remote datasets
data = hospital_A.search("#dataset-patients-processed")
target = hospital_B.search("#patients-length-of-stay")

# Send model training to another worker
model.send(data.location)

# On all client workers run PyTorch normally except use pointers instead of tensors
optimizer.zero_grad()
output = model(data) # predict length of stay
loss = F.nll_loss(output, target) # compute loss
loss.backward()
optimizer.step() # update

model.get() # local update
```

3. **Privacy**: Moment accountant monitors privacy of each client using differential privacy.
4. **Mutual trust**: Both model parameters and data are put through MPC. While all clients can decrypt the MPC data/model by collaborating, it is still not possible to recover the data because of additional security from differential privacy.

### References

1. Open-source tool to convert standard databases into FHIR standard format: https://github.com/arkhn/pyrog
2. Convert FHIR database into ML-friendly format: https://github.com/arkhn/FHIR2Dataset
3. PySyft: https://github.com/OpenMined/PySyft
4. OpenMined project: https://www.openmined.org/
5. [Dwork C, Roth A. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science. 2014 Aug 11;9(3-4):211-407.](https://www.tau.ac.il/~saharon/BigData2015/privacybook.pdf)
6. [Abadi M, Chu A, Goodfellow I, McMahan HB, Mironov I, Talwar K, Zhang L. Deep learning with differential privacy. InProceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security 2016 Oct 24 (pp. 308-318).](https://dl.acm.org/doi/pdf/10.1145/2976749.2978318)
7. [Ryffel T, Pointcheval D, Bach F. ARIANN: Low-Interaction Privacy-Preserving Deep Learning via Function Secret Sharing. arXiv preprint arXiv:2006.04593. 2020 Jun 8.](https://arxiv.org/pdf/2006.04593.pdf)

____

## Two-stage Federated Phenotyping and Patient Representation Learning

### Why?

1. ML model training requires a lot of data. But data privacy laws like HIPAA in the US and GDPR in the European Union, make it challenging to share medical data from different silos.
2. **Clinical notes** contain a rich and reliable source of health data. Notes include discharge summaries, nursing notes, and notes from different specialists. Clinical notes are highly confidential. But access to such data for ML algorithms can help realize *precision medicine*.
3. **Standardization for Federated Learning**: Architecture for collaboration may already be in place, for example— [i2b2 network](https://www.i2b2.org/), [ACT network](https://www.ctsi.umn.edu/consultations-and-services/multi-site-study-support/accrual-clinical-trials-act-network), and [UDN network](https://undiagnosed.hms.harvard.edu/). Additionally, [HL7 FHIR](https://www.hl7.org/fhir/) can help specify stadardized data formats for various clients in a federation system.

### Who?

[Dianbo Liu](https://scholar.harvard.edu/dianboliu/bio) is a research fellow in Computational Health Informatics Program (CHIP) at Harvard Medical School and Boston Childrens's Hospital.

### What?

1. **Two-stage Federated Phenotyping and Patient Representation Learning**: This federated learning system occurs in two stages—
   1. *Stage 1* (**Patient Representation Learning**): In this step, guided by a medical expert, clinical notes are parsed to identify medical concepts. Medical concepts are encoded using their UMLS Concept Unique Identifiers (CUIs). CUIs are encoded using a word embedding. Embedding is trained in a supervised way using ICD/CPT codes relevant to a patient during their visit, when the notes were taken. The layers before the output layer (ICD/CPT code vector) is used as a patient representation.
   2. *Stage 2* (**Phenotype Learning**): Trained embedded takes clinical notes as input and predicts phenotype as output.

### How?

1. Method was tested on  the open source i2b2 MIMIC dataset. Various phenotypes were chosen for evaluation.
2. They evaluated 3 types of patient representation learning— 1) bag-of-CUIs, 2) embedding from centralized data, and 3) embedding from federated data. For each, they evaluated two types of learning on phenotypes— 1) centralized training, and 2) federated training.
3. Model with patient representations learned using federated system and phenotype learning using the federated system outperformed all the other evaluated model combinations on Precision, Recall, and F1 score. The result was consistently good for various phenotypes.

### References

1. [Liu D, Dligach D, Miller T. Two-stage federated phenotyping and patient representation learning. arXiv preprint arXiv:1908.05596. 2019 Aug 14.](https://arxiv.org/pdf/1908.05596.pdf)
2. The source code will be made available at: https://github.com/kaiyuanmifen/FederatedNLP

____

## Split Learning and NoPeek for Resource Efficient Distributed Deep Learning

### Why?

1. **Goal of distributed computing**: How can we effectively enable individual, organizational, regional, national, and global collaboration through data and intelligence sharing, without infringing privacy, security, safety, trust, and regulation?
2. **Resource efficiency**: For a solution to be widely deployed, it needs to be resource efficient. It should work in situations like low availability of data, low communication bandwidth, and low compute resources.
3. **Overall goal**: Private and efficient distributed machine learning without exchnage of raw data.
4. **Challenges with existing solutions**: *Federated Learning* can be challenging in low-resource environments when deploying large models with millions of parameters.

### Who?

[Praneeth Vepakomma](https://www.media.mit.edu/people/vepakom/overview/) is a researcher at  [MIT's Camera Culture group](https://www.media.mit.edu/groups/camera-culture/overview/). He works on algorithms development for distributed and collaborative machine learning.

### What?

1. **Split learning**: The DL model is split at a designated layer called *split layer*. The server trains the lower levels (below the split layer), while the clients train the upper levels of the neural network. Only the activations from the split layer is communicated between the client and the server.
2. Various network topologies accommodate the different requirements of the implementation. For example, *vanilla topology* when raw data exists with clients but labels with the server; *boomerang topology* when both the raw data and labels exist with the clients; *vertical partitioning topology* when clients contain different subsets of features for the same set of examples; and various other hybrid topologies.
3. **Reconstruction attacks**: Input raw data can be reconstructed by an adversary who gets access to the activations being communicated.
   1. *Note*: There are other types of attacks possible, which are part of ongoing research.
4. **NoPeek method (to prevent reconstruction attacks)**: Instead of using a plain loss function like *categorical cross entropy*, add a *leakage term* to the loss function that attempts to decorrelate the input data and the activations being coimmunicated. Introduce a hyperparameter to control the amount of leakage. The leakage term can also be designed to specifically obfuscate only certain sensitive attributes.

### How?

1. Split network training reduces the amount of computation required by the clients and the amount of information that needs to be communicated between the clients and the server.
2. Split learning was evaluated on four benchmark medical imaging datasets, each modeled using large networks like VGG and ResNet. When compared with federated learning and large-scale Stochastic Gradient Descent, split learning was shown to result in significant savings in client-side computation and communication.
3. NoPeek method considerably obfuscates the input image making it very difficult to reconstruct the input data. The leakage term hyperparameter represents a tradeoff in privacy and utility. Greater the value of the hyperparameter, the greater the privacy (harder to reconstruct the input) but lower the model accuracy. Lesser the value of the hyperparameter, lower the privacy but greater the model accuracy.

### References

1. Project page: https://splitlearning.github.io/.
2. [Vepakomma P, Gupta O, Swedish T, Raskar R. Split learning for health: Distributed deep learning without sharing raw patient data. arXiv preprint arXiv:1812.00564. 2018 Dec 3.](https://arxiv.org/pdf/1812.00564.pdf)
3. Split learning is also ported into the open sourced platform PySyft (https://github.com/OpenMined/PySyft).

____

## Privacy Preserving Federated Learning

### Why?

1. **Fundamental elements of good AI**: Big data with Volume (lot of examples), Variety (captures diversity in the domain), and Velocity (capture temporal changes in the domain) and an AI solution with Visibility (Understandability to promote trust).
2. Federated Learning provides access to Big data and is a game-changer for good AI but it needs to address **security and privacy** of the siloed data and information communicated during the federation process. Possible threat vectors include possible theft of IP in form of the ML model, leakage of siloed data, model tampering, and tampering of communications.

### Who?

[Nikhil M. Deshpande](https://www.linkedin.com/in/nikhildeshpande/) is the Director of AI Solutions and Engineering at Intel Corporation.

### What?

1. **Trusted Execution Environment (TEE)**: Run TEE on both clients and servers. Uses Intel's [Software Guard Extensions SDK](https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions.html) to allow application code and data direct communication to hardware. 
2. **Homomorphic Encryption (HE)**: An important emerging encryption technology that can be an attractive solution. Allows arithmetic on encrypted data, which can be decrypted to obtain the result. HE is computationally very expensive (almost 1000x). HE must also support complex operations for decision trees, k-nearest neighbors, etc.
3. **Combination of HE and Federated Learning is truly privacy-preserving**.

### How?

1. TEE minimizes the size of trusted compute block and thereby protects data & model from software attacks from compromised stacks including hypervisors, OS, drivers, BIOS, etc. Also protects against attacks when attacker has full access to platform. TEE also provides verification/data signatures to attest the validity of the hardware.
2. HE can be used to encrypt both model and the data. Both model training and inferencing can be protected. Easy to share data with minimized risk.

### References

1. Intel's SGX Platform: https://software.intel.com/content/www/us/en/develop/topics/software-guard-extensions.html

____

## Transforming Supply Chain with Blockchain and AI

### Why?

1. According to a survey by Deloitte, Supply Chain is the largest use case of blockchain technology. **Supply Chain Management** (SCM) is the "process of planning, implementing, and controlling the operations of the supply chain with the purpose to satisfy customer requirements as efficeintly as possible. SCM spans all movement and storage of raw materials, work-in-progress inventory, and finished goods from point-of-origin to point-of-consumption".
2. **SCM traceability problem**: In China, in 2008, dairy producers laced milk and infant formula with Melamine resulting in 300,000 sick babies and 6 fatalities from kidney damage. In USA, in 2015, E. coli outbreak from food prepared at Chipotle fast-food chain. In Europe, in 2013, horse meat sold as beef. In this cases, we want to quickly trace the source of the error that led to these serious outcomes. This helps in quick diagnosis and helps prevent tainted SCM chain.

### Who?

[Aly Madhavji](https://www.linkedin.com/in/alymadhavji/) is a Managing Partner at Blockchain Founders Fund. They invest in start-ups and consult blockchain companies on emerging technologies.

### What?

1. **Blockchain**: "is a growing list of records, called *blocks*, that are linked using cryptography. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data."
2. Implemented in Walmart, China, using VeChain.
3. Is also be implemented for COVID contact tracing and for tracing medical supplies.

### How?

1. Blockchain provides transparency, accountability, and auditability. Reduces error from manual reconciliation. Provides real-time updates. Improves disclosures and accountability when interests aren't aligned.
2. Walmart store put mangoes on chain and were able to trace origin of their mangoes in 2.2 seconds, which would otherwise require 7 days.
3. JD Chain app helps customers scan items in supermarket and get details of the origin of the products like meat including the cow's breed, weight, diet, etc.

____

## Practical Explainable AI

### Why?

1. Google recently [launched an AI to predict diabetic retinopathy from eye scan](https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease). It had high accuracy in a lab but did not do well in production. Mainly because the end-users, the nurses, were not able to explain why a specific prediction was made.
2. Many historical examples exist where AI learns unexpected biases and stereotypes, thereby propagating it in production. Also, black-bos AI increases business risk.
3. **GDPR**: "Article 22 of GDPR empowers individuals with the right to demand an explanation of how an AI system made a decision that affects them."
4. AI models should be explainable (for predictions), compliant (for auditing), debuggable (diagnose errors), monitor (performance and fairness).

### Who?

[Raheel Ahmad](https://www.linkedin.com/in/raheelahmad12/) is an AI Researcher and co-founder of [explainX.ai](https://www.explainx.ai/), a start-up based on New York City with a focus on explaining black-box AI models. 

### What?

1. Attribution methods include: Ablation, Gradient-based, Backpropagation-based, Local surrogate model-based, Shapley, etc.
2. Visualization methods include: *Partial-dependence plots* (marginal effect of variables on outcome), *Summary plot* (combines feature importance and impact), *Scenario analysis* (run what-if scenarios to identify model behavior in different subsets), *Prototypical analysis* (justify model prediction by identifying similar examples in dataset and observing their outcomes), *Contrastive explanations* (which feature-value, if changed, will flip the prediction?).

### How?

1. Applied for loan application approval. When user submits request for a loan, the query is sent to AI model, the AI model sends prediction and an explanation. Gives both global (population-wise) and local-level (instance-specific) explanations.

### References

1. Open-source framework for explainable AI: https://github.com/explainX/explainx